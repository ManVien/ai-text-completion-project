{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f677b641-92e9-4d66-a269-fdfb504cc692",
   "metadata": {},
   "source": [
    "# Objective\r\n",
    "The goal of this project is to give you hands-on experience with Generative AI by building and experimenting with a simple text completion application. You will\n",
    "\n",
    "- Understand how Generative AI processes input prompts to generate coherent and relevant text.\n",
    "- Set up and interact with a pre-trained AI model through an API.\n",
    "- Experiment with prompt design and model parameters to evaluate output quality.\n",
    "- Reflect on the capabilities and limitations of the AI model.:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1be414-4a17-44de-89ec-6f7a1c437b9f",
   "metadata": {},
   "source": [
    "# Project Details\r\n",
    "You will create a Python-based application that interacts with a pre-trained Generative AI model (such as OpenAI's GPT or similar models from Cohere, Hugging Face, etc.). Your application will accept user input, send it to the model, and return a completed or generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "235ceeea-b25a-4c9b-a0a9-2fc79c6450a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cohere\n",
      "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
      "  Downloading fastavro-1.11.1-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from cohere) (0.27.0)\n",
      "Collecting httpx-sse==0.4.0 (from cohere)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from cohere) (2.5.3)\n",
      "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere)\n",
      "  Downloading pydantic_core-2.35.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from cohere) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from cohere) (0.21.1)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
      "  Downloading types_requests-2.32.4.20250611-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from cohere) (4.11.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from httpx>=0.21.2->cohere) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from httpx>=0.21.2->cohere) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.6.0)\n",
      "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pydantic>=1.9.2 (from cohere)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "     ---------------------------------------- 0.0/68.0 kB ? eta -:--:--\n",
      "     ------------------------ --------------- 41.0/68.0 kB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 68.0/68.0 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing_extensions>=4.0.0 (from cohere)\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=1.9.2->cohere)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from tokenizers<1,>=0.15->cohere) (0.33.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\leblu\\downloads\\anaconda\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n",
      "Downloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
      "   ---------------------------------------- 0.0/259.5 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 174.1/259.5 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  256.0/259.5 kB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 259.5/259.5 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading fastavro-1.11.1-cp312-cp312-win_amd64.whl (442 kB)\n",
      "   ---------------------------------------- 0.0/442.8 kB ? eta -:--:--\n",
      "   -------------------------------- ------ 368.6/442.8 kB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 442.8/442.8 kB 5.5 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "   ---------------------------------------- 0.0/444.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 444.8/444.8 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.0 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.4/2.0 MB 17.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 17.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 12.5 MB/s eta 0:00:00\n",
      "Downloading types_requests-2.32.4.20250611-py3-none-any.whl (20 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing_extensions, types-requests, httpx-sse, fastavro, typing-inspection, pydantic-core, pydantic, cohere\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.3\n",
      "    Uninstalling pydantic-2.5.3:\n",
      "      Successfully uninstalled pydantic-2.5.3\n",
      "Successfully installed cohere-5.15.0 fastavro-1.11.1 httpx-sse-0.4.0 pydantic-2.11.7 pydantic-core-2.33.2 types-requests-2.32.4.20250611 typing-inspection-0.4.1 typing_extensions-4.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add929f5-1b6e-41c0-b46e-ae1100f85c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Generative AI Text Completion App (Cohere Chat API)!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  Once upon a time, there was a robot whoâ€¦\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " Once upon a time, there was a robot named Zeta who lived in a bustling city of gleaming metal towers and humming machinery. Unlike the other robots, who followed their daily routines with precision, Zeta had a curious spark in its circuits. It often wondered about the world beyond the cityâ€”the forests, the oceans, and the creatures that lived there.\n",
      "\n",
      "One day, while sorting through a pile of discarded parts, Zeta found an old, dusty book titled *\"The Wonders of Nature.\"* Its pages were filled with vibrant illustrations of flowers, birds, and sunsets. Zeta was captivated. It began to dream of seeing these wonders for itself.\n",
      "\n",
      "Determined to explore, Zeta set off on a journey, leaving the familiar hum of the city behind. It traveled through dense forests, where it marveled at the towering trees and the songs of unseen birds. It crossed rivers, feeling the cool water on its metallic feet, and climbed mountains, where the air was thin but the views were breathtaking.\n",
      "\n",
      "Along the way, Zeta met creatures it had only read aboutâ€”a wise old owl, a playful fox, and even a shy deer. Each encounter taught Zeta something new about the world and about itself. The robot learned that kindness, curiosity, and connection were just as important as logic and efficiency.\n",
      "\n",
      "When Zeta finally returned to the city, it wasnâ€™t the same robot that had left. Its once-pristine exterior was now scratched and weathered, but its heartâ€”or rather, its coreâ€”was richer than ever. Zeta shared its stories with the other robots, inspiring them to look beyond their routines and embrace the wonders of the world.\n",
      "\n",
      "And so, Zeta became a symbol of curiosity and courage, proving that even a robot could find magic in the simplest of things. From that day on, the city buzzed not just with the sound of machinery, but with the whispers of dreams and the promise of adventure.  \n",
      "\n",
      "The end.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  Explain photosynthesis to a 10-year-old.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " Sure! Imagine you have a tiny factory inside the leaves of plants. This factory is super special because it can make food for the plant, just like how a kitchen makes food for you. But instead of using pots and pans, this factory uses sunlight, water, and air.\n",
      "\n",
      "Hereâ€™s how it works:\n",
      "\n",
      "1. **Sunlight**: The plant catches sunlight with its leaves, just like how you might catch a ball with your hands. The sunlight is like the energy that powers the factory.\n",
      "\n",
      "2. **Water**: The plant drinks water from the ground through its roots, kind of like how you drink water with a straw. The water travels up to the leaves.\n",
      "\n",
      "3. **Air**: The plant takes in a special gas from the air called carbon dioxide. You breathe out carbon dioxide when you exhale, and plants love it!\n",
      "\n",
      "4. **Magic Happens**: Inside the leaves, the sunlight, water, and carbon dioxide mix together in a special way. This process makes two important things:\n",
      "   - **Glucose**: This is like plant food, which gives the plant energy to grow.\n",
      "   - **Oxygen**: This is a gas that plants release into the air, and itâ€™s what you and I breathe in to stay alive!\n",
      "\n",
      "So, photosynthesis is like a plantâ€™s way of making its own lunch while also giving us the air we need to breathe. Pretty cool, right?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  Write a haiku about the ocean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " Waves whisper secrets,  \n",
      "Endless blue meets boundless sky,  \n",
      "Lifeâ€™s rhythm in tide.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  Continue this story \"Adam has an apple, while Elsa doesn't have an apple\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " Adam, noticing Elsa's empty hands, felt a pang of guilt. He had always been taught to share, especially with those who had less. \"Elsa,\" he said, holding out the shiny red apple, \"would you like this? It's the sweetest one I've ever found.\"\n",
      " Elsa's eyes widened, a mix of surprise and gratitude washing over her face. \"Really? You'd share your apple with me?\"\n",
      "\n",
      "Adam nodded, a warm smile spreading across his face. \"Of course! Sharing is what makes things taste even better.\"\n",
      " Elsa took the apple gently, its coolness a welcome contrast to the warmth of Adam's generosity. \"Thank you, Adam. This means a lot.\"\n",
      "\n",
      "As they sat down together under the shade of an old oak tree, Adam realized something. The apple, once a simple fruit, had become a symbol of their growing friendship. It wasn't about having or not having anymore; it was about the connection they were forming, one bite at a time.\n",
      "\n",
      "From that day on, Adam and Elsa shared more than just apples â€“ they shared stories, laughter, and a bond that would last a lifetime. And though they would face many challenges together, they knew that as long as they had each other, they would always find a way to share the sweetness of life.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  Explain recursion like Iâ€™m five.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      " Okay! Imagine youâ€™re building a tower with blocks. You start with one block, then you add another on top, and another, and so on. But letâ€™s say you have a special rule: every time you add a block, you first check if the tower is tall enough. If itâ€™s not, you add *another block in the same way*â€”checking again if itâ€™s tall enough, and if not, adding another block, and so on.\n",
      "\n",
      "Thatâ€™s **recursion**! Itâ€™s like a rule that keeps using itself until the job is done. You keep repeating the same step (adding a block and checking) until you reach the goal (the tower is tall enough). When you finally reach the goal, you stop and go back to all the steps you were saving up, like climbing back down the tower.\n",
      "\n",
      "So, recursion is like a game of \"keep doing this until youâ€™re done,\" and then you clean up all the steps you took to get there. Cool, right?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your prompt (or type 'exit' to quit):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Load API key securely from environment variable\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# Validate API key presence\n",
    "if not api_key:\n",
    "    print(\"Error: COHERE_API_KEY not found. Please set your environment variable.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Initialize Cohere client\n",
    "co = cohere.Client(api_key)\n",
    "\n",
    "def text_completion():\n",
    "    print(\"Welcome to Generative AI Text Completion App (Cohere Chat API)!\")\n",
    "    \n",
    "    # Open a log file to record conversation\n",
    "    with open(\"conversation_log.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"\\n--- New Session: {datetime.now()} ---\\n\")\n",
    "        \n",
    "        while True:\n",
    "            prompt = input(\"\\nEnter your prompt (or type 'exit' to quit): \").strip()\n",
    "            \n",
    "            if prompt.lower() == \"exit\":\n",
    "                print(\"Goodbye!\")\n",
    "                log_file.write(\"Session ended by user.\\n\")\n",
    "                break\n",
    "            if not prompt:\n",
    "                print(\"Prompt cannot be empty. Please try again.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Use Chat API\n",
    "                response = co.chat(\n",
    "                    model='command-nightly',\n",
    "                    message=prompt,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                output = response.text.strip()\n",
    "                print(\"\\nAI Response:\\n\", output)\n",
    "\n",
    "                # Record prompt and response to log file\n",
    "                log_file.write(\"\\n------------------------------\\n\")\n",
    "                log_file.write(f\"\\nPrompt: {prompt}\\n\")\n",
    "                log_file.write(f\"Response: {output}\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                log_file.write(f\"Error: {e}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    text_completion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
